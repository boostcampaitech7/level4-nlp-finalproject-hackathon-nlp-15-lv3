from langchain.vectorstores import Chroma
from chromadb.config import Settings
from transformers import AutoTokenizer, AutoModel
import torch
from langchain.embeddings.base import Embeddings
from typing import List

# kakaobank/kf-deberta-base ëª¨ë¸ ì´ˆê¸°í™”
deberta_model_name = "kakaobank/kf-deberta-base"
tokenizer = AutoTokenizer.from_pretrained(deberta_model_name)
model = AutoModel.from_pretrained(deberta_model_name)

# ChromaDB ì €ì¥ ê²½ë¡œ
CHROMA_DB_DIR = "/data/ephemeral/VectorDB/kffDB"

class DeBERTaEmbeddingFunction(Embeddings):
    """DeBERTaë¥¼ ì´ìš©í•œ ChromaDB ì„ë² ë”© í•¨ìˆ˜"""

    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì…ë ¥ë°›ì•„ ì„ë² ë”© ë²¡í„° ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜"""
        return generate_text_embeddings(texts)

    def embed_query(self, text: str) -> List[float]:
        """ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ì…ë ¥ë°›ì•„ ì„ë² ë”© ë²¡í„°ë¥¼ ë°˜í™˜"""
        return generate_text_embeddings([text])[0]

# DeBERTaë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±
def generate_text_embeddings(texts: List[str]) -> List[List[float]]:
    """DeBERTaë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±"""
    embeddings = []
    for text in texts:
        if not text.strip():
            embeddings.append([0] * 768)  # DeBERTa ì„ë² ë”© í¬ê¸°
            continue
        inputs = tokenizer(text, return_tensors="pt", padding=True, truncation=True, max_length=512)
        with torch.no_grad():
            outputs = model(**inputs)
        embeddings.append(outputs.last_hidden_state[:, 0, :].squeeze().tolist())
    return embeddings

# ChromaDBì—ì„œ ê²€ìƒ‰ ìˆ˜í–‰
def search_in_chromadb(query: str, collection_name: str, top_k: int = 3):
    """ì €ì¥ëœ ChromaDBì—ì„œ ê²€ìƒ‰í•˜ë©°, ìœ ì‚¬ë„ í•„í„° ì—†ì´ ìƒìœ„ Kê°œ ê²°ê³¼ ë°˜í™˜."""
    print("ğŸ”„ ChromaDB ì—°ê²° ì¤‘...")

    # ChromaDB ë¡œë“œ
    vectorstore = Chroma(
        collection_name=collection_name,
        embedding_function=DeBERTaEmbeddingFunction(),
        persist_directory=CHROMA_DB_DIR,
    )

    # âœ… ChromaDBì— ì €ì¥ëœ ë°ì´í„° ê°œìˆ˜ í™•ì¸
    num_docs = vectorstore._collection.count()
    print(f"âœ… í˜„ì¬ ì €ì¥ëœ ë¬¸ì„œ ê°œìˆ˜: {num_docs}")

    if num_docs == 0:
        print("âŒ ChromaDBì— ì €ì¥ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
        return []

    # âœ… ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
    query_embedding = generate_text_embeddings([query])[0]
    print("âœ… ìƒì„±ëœ ì¿¼ë¦¬ ì„ë² ë”© ê¸¸ì´:", len(query_embedding))

    # ğŸ” ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰ ìˆ˜í–‰
    results_with_scores = vectorstore._collection.query(
        query_embeddings=[query_embedding],
        n_results=top_k
    )

    # âœ… ê²€ìƒ‰ëœ ë¬¸ì„œì™€ ê±°ë¦¬ ê°’ í™•ì¸
    documents = results_with_scores["documents"][0]

    print(f"âœ… ê²€ìƒ‰ëœ ë¬¸ì„œ (ìµœëŒ€ {top_k}ê°œ):", documents[:top_k])

    # âœ… ê²€ìƒ‰ ê²°ê³¼ ë³€í™˜
    detailed_results = []
    for result in documents:
        answer = f"""
        ğŸ” ê²€ìƒ‰ëœ ë¬¸ì„œ:
        ----------------------------
        ğŸ“œ **ë‚´ìš©:** {result}  
        ----------------------------
        """
        detailed_results.append(answer)

    return detailed_results
