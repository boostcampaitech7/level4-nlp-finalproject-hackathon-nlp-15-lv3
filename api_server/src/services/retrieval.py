from langchain_community.vectorstores import Chroma
from transformers import AutoTokenizer, AutoModel
import torch
from langchain.embeddings.base import Embeddings
from typing import List, Dict, Any
import logging
import numpy as np

from core.config import settings
from models import Document, RetrievalOutput  # Add this import
logger = logging.getLogger(__name__)


# kakaobank/kf-deberta-base ëª¨ë¸ ì´ˆê¸°í™”
deberta_model_name = "kakaobank/kf-deberta-base"
tokenizer = AutoTokenizer.from_pretrained(deberta_model_name)
model = AutoModel.from_pretrained(deberta_model_name)

# ChromaDB ì €ì¥ ê²½ë¡œ
CHROMA_DB_DIR = settings.vector_db["chroma_db_dir"]

class DeBERTaEmbeddingFunction(Embeddings):
    """DeBERTaë¥¼ ì´ìš©í•œ ChromaDB ì„ë² ë”© í•¨ìˆ˜"""

    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì…ë ¥ë°›ì•„ ì„ë² ë”© ë²¡í„° ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜"""
        return generate_text_embeddings(texts)

    def embed_query(self, text: str) -> List[float]:
        """ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ì…ë ¥ë°›ì•„ ì„ë² ë”© ë²¡í„°ë¥¼ ë°˜í™˜"""
        return generate_text_embeddings([text])[0]

# DeBERTaë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±
def generate_text_embeddings(texts: List[str]) -> List[List[float]]:
    """DeBERTaë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±"""
    embeddings = []
    for text in texts:
        if not text.strip():
            embeddings.append([0] * 768)  # DeBERTa ì„ë² ë”© í¬ê¸°
            continue
        inputs = tokenizer(text, return_tensors="pt", padding=True, truncation=True, max_length=512)
        with torch.no_grad():
            outputs = model(**inputs)
        embeddings.append(outputs.last_hidden_state[:, 0, :].squeeze().tolist())
    return embeddings

#FIXME ì§€ë‚˜ì¹˜ê²Œ ë†’ì€ ê±°ë¦¬ê°’
def l2_to_similarity(l2_distance: float) -> float:
    return 1 / (1 + l2_distance)

# ChromaDBì—ì„œ ê²€ìƒ‰ ìˆ˜í–‰
def search_in_chromadb(
    query: str, 
    collection_name: str = settings.collection_name, 
    top_k: int = 3
) -> RetrievalOutput:
    """ì €ì¥ëœ ChromaDBì—ì„œ ê²€ìƒ‰í•˜ë©°, ìœ ì‚¬ë„ í•„í„° ì—†ì´ ìƒìœ„ Kê°œ ê²°ê³¼ ë°˜í™˜."""
    try:
        logger.info("ğŸ”„ ChromaDB ì—°ê²° ì¤‘...")
        vectorstore = Chroma(
            collection_name=collection_name,
            embedding_function=DeBERTaEmbeddingFunction(),
            persist_directory=CHROMA_DB_DIR,
        )

        num_docs = vectorstore._collection.count()
        logger.info(f"âœ… {collection_name} í˜„ì¬ ì €ì¥ëœ ë¬¸ì„œ ê°œìˆ˜: {num_docs}")

        if num_docs == 0:
            logger.warning("âŒ ChromaDBì— ì €ì¥ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return RetrievalOutput(
                id="empty",
                name="empty",
                group_id="empty",
                related_documents=[Document(
                    id="empty_doc",
                    text="í˜„ì¬ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”.",
                    metadata={},
                    score=0.0
                )]
            )

        # âœ… ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
        query_embedding = generate_text_embeddings([query])[0]
        logger.info(f"âœ… ìƒì„±ëœ ì¿¼ë¦¬ ì„ë² ë”© ê¸¸ì´: {len(query_embedding)}")

        # ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰ ìˆ˜í–‰
        results = vectorstore._collection.query(
            query_embeddings=[query_embedding],
            n_results=top_k
        )

        # ê²°ê³¼ ë³€í™˜
        documents = []
        for idx, (doc, distance) in enumerate(zip(results["documents"][0], results["distances"][0])):
            similarity = l2_to_similarity(distance)
            logger.info(f"Document {idx}: L2 distance = {distance:.4f}, Similarity = {similarity:.4f}")
            documents.append(Document(
                id=f"doc_{idx}",
                text=doc,
                metadata={},
                score=similarity  # ë³€í™˜ëœ ìœ ì‚¬ë„ ì ìˆ˜ ì‚¬ìš©
            ))

        return RetrievalOutput(
            id="search_result",
            name="search",
            group_id="search",
            related_documents=documents
        )

    except Exception as e:
        logger.error(f"ChromaDB ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return RetrievalOutput(
            id="error",
            name="error",
            group_id="error",
            related_documents=[Document(
                id="error_doc",
                text="ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                metadata={},
                score=0.0
            )]
        )
