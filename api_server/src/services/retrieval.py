from langchain_community.vectorstores import Chroma
from transformers import AutoTokenizer, AutoModel
import torch
from langchain.embeddings.base import Embeddings
from typing import List, Dict, Any
import logging

from core.config import settings
from utils import RetrievalOutput  # Add this import
logger = logging.getLogger(__name__)


# kakaobank/kf-deberta-base ëª¨ë¸ ì´ˆê¸°í™”
deberta_model_name = "kakaobank/kf-deberta-base"
tokenizer = AutoTokenizer.from_pretrained(deberta_model_name)
model = AutoModel.from_pretrained(deberta_model_name)

# ChromaDB ì €ì¥ ê²½ë¡œ
CHROMA_DB_DIR = settings.vector_db["chroma_db_dir"]

class DeBERTaEmbeddingFunction(Embeddings):
    """DeBERTaë¥¼ ì´ìš©í•œ ChromaDB ì„ë² ë”© í•¨ìˆ˜"""

    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì…ë ¥ë°›ì•„ ì„ë² ë”© ë²¡í„° ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜"""
        return generate_text_embeddings(texts)

    def embed_query(self, text: str) -> List[float]:
        """ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ì…ë ¥ë°›ì•„ ì„ë² ë”© ë²¡í„°ë¥¼ ë°˜í™˜"""
        return generate_text_embeddings([text])[0]

# DeBERTaë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±
def generate_text_embeddings(texts: List[str]) -> List[List[float]]:
    """DeBERTaë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±"""
    embeddings = []
    for text in texts:
        if not text.strip():
            embeddings.append([0] * 768)  # DeBERTa ì„ë² ë”© í¬ê¸°
            continue
        inputs = tokenizer(text, return_tensors="pt", padding=True, truncation=True, max_length=512)
        with torch.no_grad():
            outputs = model(**inputs)
        embeddings.append(outputs.last_hidden_state[:, 0, :].squeeze().tolist())
    return embeddings

# ChromaDBì—ì„œ ê²€ìƒ‰ ìˆ˜í–‰
def search_in_chromadb(
    query: str, 
    collection_name: str = settings.collection_name, 
    top_k: int = 3
) -> RetrievalOutput:
    """ì €ì¥ëœ ChromaDBì—ì„œ ê²€ìƒ‰í•˜ë©°, ìœ ì‚¬ë„ í•„í„° ì—†ì´ ìƒìœ„ Kê°œ ê²°ê³¼ ë°˜í™˜."""
    try:
        logger.info("ğŸ”„ ChromaDB ì—°ê²° ì¤‘...")
        vectorstore = Chroma(
            collection_name=collection_name,
            embedding_function=DeBERTaEmbeddingFunction(),
            persist_directory=CHROMA_DB_DIR,
        )

        num_docs = vectorstore._collection.count()
        logger.info(f"âœ… {collection_name} í˜„ì¬ ì €ì¥ëœ ë¬¸ì„œ ê°œìˆ˜: {num_docs}")

        if num_docs == 0:
            logger.warning("âŒ ChromaDBì— ì €ì¥ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return RetrievalOutput(
                id="empty",
                name="empty",
                group_id="empty",
                related_documents=[{
                    "id": "empty_doc",  # Added id field
                    "text": "í˜„ì¬ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”.",
                    "metadata": {},
                    "score": 0
                }]
            )

        # âœ… ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
        query_embedding = generate_text_embeddings([query])[0]
        logger.info(f"âœ… ìƒì„±ëœ ì¿¼ë¦¬ ì„ë² ë”© ê¸¸ì´: {len(query_embedding)}")

        # ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰ ìˆ˜í–‰
        results = vectorstore._collection.query(
            query_embeddings=[query_embedding],
            n_results=top_k
        )

        # ê²°ê³¼ ë³€í™˜
        documents = []
        for idx, (doc, score) in enumerate(zip(results["documents"][0], results["distances"][0])):
            documents.append({
                "id": f"doc_{idx}",  # Added unique id for each document
                "text": doc,
                "metadata": {},
                "score": float(score)
            })

        return RetrievalOutput(
            id="search_result",
            name="search",
            group_id="search",
            related_documents=documents
        )

    except Exception as e:
        logger.error(f"ChromaDB ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return RetrievalOutput(
            id="error",
            name="error",
            group_id="error",
            related_documents=[{
                "id": "error_doc",  # Added id field
                "text": "ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                "metadata": {},
                "score": 0
            }]
        )
